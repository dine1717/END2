{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP5miZPg5N/lbO+7X1Zcu0f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dine1717/END2/blob/session11/Session11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M5uG4td-STL"
      },
      "source": [
        "#  Sequence to Sequcen and Attention Mechanish\n",
        "In this code we'll we will dig much deeper and try and come up with the model ourselves. We will see the steps required to do so.\n",
        "\n",
        "For the actual model refer to this colab link.\n",
        "\n",
        "The part we are going to borrow from the code above is the data-preprocessing as that is straight forward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpgqVFtN97ob"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvyS1pbWd8fs"
      },
      "source": [
        "#  Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayz1o6CZd63C"
      },
      "source": [
        "# !wget https://download.pytorch.org/tutorial/data.zip\n",
        "# !unzip data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mExuX4--Sza"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s5fwDileBJq",
        "outputId": "f7722c61-1bc0-473e-8b03-b12f7a006a38"
      },
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4345\n",
            "eng 2803\n",
            "['ils sont tous la .', 'they re all here .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP5dfee5hxUY"
      },
      "source": [
        "*italicised text*### Randomly pick one of the sample  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLYmdXRPBNEO",
        "outputId": "8cb18e38-c905-47f3-ee08-0b289ecc4117"
      },
      "source": [
        "sample = random.choice(pairs)\n",
        "sample"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['je suis desireux de vous aider .', 'i am willing to help you .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7gNY0LvBU8X",
        "outputId": "4f03b88c-555c-4b3f-f441-2aea18b9dcb1"
      },
      "source": [
        "input_sentence = sample[0]\n",
        "output_sentence = sample[1]\n",
        "## Get the index of the word \n",
        "input_lang.word2index[\"vous\"]"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47bIgJdTbtFX"
      },
      "source": [
        "### Get the indices of the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEeY3SPlB2Ka",
        "outputId": "36de1b81-ab16-4f1d-9978-cedd7871ccf4"
      },
      "source": [
        "input_indices = [input_lang.word2index[word] for word in input_sentence.split(' ')]\n",
        "target_indices = [output_lang.word2index[word] for word in output_sentence.split(' ')]\n",
        "input_indices,target_indices"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([6, 11, 2997, 101, 118, 1926, 5], [2, 16, 1302, 532, 571, 129, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCcbr61Kb0zB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1cJmTf0CVkw",
        "outputId": "e8143f83-3468-4346-9971-658bcb502ff5"
      },
      "source": [
        "input_indices.append(EOS_token)\n",
        "target_indices.append(SOS_token)\n",
        "input_indices,target_indices"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([6, 11, 2997, 101, 118, 1926, 5, 1], [2, 16, 1302, 532, 571, 129, 4, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDWbu_ixC2Nc"
      },
      "source": [
        "Oh yes, these are still indeces (not words anymore), we first need to convert them to tensors.\n",
        "\n",
        "In the original code we wrote these 3 functions to take care of all the work we did till now.\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        " \n",
        " \n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        " \n",
        " \n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRaBpdrMCtIL",
        "outputId": "1dc9ca7d-f500-44ee-b8e4-fb22bf2962ef"
      },
      "source": [
        "# input_indices.append(EOS_token)\n",
        "# target_indices.append(SOS_token)\n",
        "input_indices,target_indices"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([6, 11, 2997, 101, 118, 1926, 5, 1], [2, 16, 1302, 532, 571, 129, 4, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvCx2mphDCZQ"
      },
      "source": [
        "input_tensor = torch.tensor(input_indices,dtype=torch.long,device=device)\n",
        "output_tensor = torch.tensor(target_indices,dtype=torch.long,device=device)"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HBZ1z68DSP4",
        "outputId": "abd33258-7511-49d5-c77e-190296d8af09"
      },
      "source": [
        "input_tensor.shape,output_tensor.shape"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8]), torch.Size([8]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN5eB8PdDdEz",
        "outputId": "047c2724-590e-4de5-fba8-d834d38081e1"
      },
      "source": [
        "device"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJC-djkXcFlP"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkFWYpeecLLU"
      },
      "source": [
        "input_size = input_lang.n_words\n",
        "hidden_size = 256"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlFIDTUoD8RH"
      },
      "source": [
        "embedding = nn.Embedding(input_size,hidden_size).to(device)\n",
        "lstm = nn.LSTM(hidden_size,hidden_size).to(device)"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxthyOfFEIXO",
        "outputId": "0d62fd3e-280e-4883-b823-667d53efc118"
      },
      "source": [
        "embedded_input = embedding(input_tensor)\n",
        "embedded_input.shape"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDc4Bo_xEJaM",
        "outputId": "2539fb31-6feb-484b-a5f4-36fad6f059db"
      },
      "source": [
        "input_tensor"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   6,   11, 2997,  101,  118, 1926,    5,    1], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL5f5sShETgY",
        "outputId": "3e8037d7-d670-4bd4-9b2d-12ce09e3b65b"
      },
      "source": [
        "input_tensor.shape, input_tensor.view(-1,1).shape"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8]), torch.Size([8, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pkccgEqFQfD",
        "outputId": "0a538c17-2957-4598-9a2b-d266b91d595e"
      },
      "source": [
        "print(embedded_input.shape)\n",
        "embedded_input = embedding(input_tensor.view(-1,1))\n",
        "print(embedded_input.shape)"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 256])\n",
            "torch.Size([8, 1, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4Yuni_JFbTw",
        "outputId": "1e0f90ed-8116-49c8-af1a-acb27f2a7343"
      },
      "source": [
        "print(embedded_input.shape)\n",
        "embedded_input = embedding(input_tensor[0].view(-1,1)) ## sending each word separetly\n",
        "print(embedded_input.shape)"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 256])\n",
            "torch.Size([1, 1, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RspM3b7YF4kY"
      },
      "source": [
        "hidden = torch.zeros(1,1,256,device =device)\n",
        "cell = torch.zeros(1,1,256,device =device)"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrDOiNUMGB30"
      },
      "source": [
        "embedded_input = embedding(input_tensor[0].view(-1,1)) ## sending each word separetly\n",
        "output,(hidden,cell) = lstm(embedded_input,(hidden,cell))"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQysS0wpGKbE",
        "outputId": "78873e14-00b2-4fe7-e7f4-9955373dcbe6"
      },
      "source": [
        "output.shape, output[0,0].shape"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 256]), torch.Size([256]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "royI19dMeu_Q"
      },
      "source": [
        "MAX_LENGTH = input_tensor.size()[0]"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r5Knp9CG3_Y",
        "outputId": "63598853-6466-4d0f-ca46-674c6bd199fc"
      },
      "source": [
        "encoder_outputs = torch.zeros(MAX_LENGTH,256,device = device )\n",
        "encoder_outputs.shape"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7yPtirzJQts",
        "outputId": "7bcc8bf5-0159-4345-e6c3-71a6e3df46ad"
      },
      "source": [
        "input_tensor.size(),input_tensor.size()[0]"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8]), 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzN3HSy2JZih"
      },
      "source": [
        "encoder_outputs = torch.zeros(MAX_LENGTH, 256, device=device)\n",
        "# >>> output[0, 0].shape\n",
        "# torch.Size([256]))\n",
        "encoder_hidden = torch.zeros(1, 1, 256, device=device)\n",
        "encoder_cell = torch.zeros(1,1,256,device =device)\n",
        "\n",
        "for i in range(input_tensor.size()[0]):\n",
        "  # print(input_sentence.split(' ')[i]) why will this cause error?\n",
        "  embedded_input = embedding(input_tensor[i].view(-1, 1))\n",
        "  output, (encoder_hidden,encoder_cell) = lstm(embedded_input, (encoder_hidden,encoder_cell))\n",
        "  encoder_outputs[i] += output[0,0]\n"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1LP5F-Gct_a"
      },
      "source": [
        "encoder_outputs = torch.zeros(MAX_LENGTH, 256, device=device)\n",
        "encoder_hidden = torch.zeros(1, 1, 256, device=device)\n",
        "encoder_cell = torch.zeros(1,1,256,device =device)"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gxauL-Ec-8H"
      },
      "source": [
        "### Feed Forward Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Z4WVQHct8q"
      },
      "source": [
        "embedded_input = embedding(input_tensor[0].view(-1, 1))\n",
        "output, (encoder_hidden,encoder_cell) = lstm(embedded_input, (encoder_hidden,encoder_cell))\n",
        "encoder_outputs[0] += output[0,0]"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDkrxTuFdGr0"
      },
      "source": [
        "embedded_input = embedding(input_tensor[1].view(-1, 1))\n",
        "output, (encoder_hidden,encoder_cell) = lstm(embedded_input, (encoder_hidden,encoder_cell))\n",
        "encoder_outputs[1] += output[0,0]"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz50mD9PKJys"
      },
      "source": [
        "embedded_input = embedding(input_tensor[2].view(-1, 1))\n",
        "output, (encoder_hidden,encoder_cell) = lstm(embedded_input, (encoder_hidden,encoder_cell))\n",
        "encoder_outputs[2] += output[0,0]\n"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfml-X8idVpx"
      },
      "source": [
        "embedded_input = embedding(input_tensor[3].view(-1, 1))\n",
        "output, (encoder_hidden,encoder_cell) = lstm(embedded_input, (encoder_hidden,encoder_cell))\n",
        "encoder_outputs[3] += output[0,0]\n"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i164Y9vhdXtY"
      },
      "source": [
        "embedded_input = embedding(input_tensor[4].view(-1, 1))\n",
        "output, (encoder_hidden,encoder_cell) = lstm(embedded_input, (encoder_hidden,encoder_cell))\n",
        "encoder_outputs[4] += output[0,0]\n"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mskqfEyqdZel"
      },
      "source": [
        "embedded_input = embedding(input_tensor[5].view(-1, 1))\n",
        "output, (encoder_hidden,encoder_cell) = lstm(embedded_input, (encoder_hidden,encoder_cell))\n",
        "encoder_outputs[5] += output[0,0]\n"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ2ze5y2rc-j"
      },
      "source": [
        "embedded_input = embedding(input_tensor[6].view(-1, 1))\n",
        "output, (encoder_hidden,encoder_cell) = lstm(embedded_input, (encoder_hidden,encoder_cell))\n",
        "encoder_outputs[6] += output[0,0]"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nrsPbKfrfKY"
      },
      "source": [
        "embedded_input = embedding(input_tensor[7].view(-1, 1))\n",
        "output, (encoder_hidden,encoder_cell) = lstm(embedded_input, (encoder_hidden,encoder_cell))\n",
        "encoder_outputs[7] += output[0,0]"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyARy1B4KL6v",
        "outputId": "2350217c-f793-42a7-8165-86827b1d240f"
      },
      "source": [
        "encoder_outputs[1:8]"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2009, -0.2267, -0.1101,  ...,  0.1206, -0.1139, -0.0528],\n",
              "        [-0.1905, -0.1416,  0.0205,  ..., -0.0568, -0.0424, -0.0385],\n",
              "        [ 0.1225, -0.3578,  0.1118,  ...,  0.0467,  0.0356, -0.1140],\n",
              "        ...,\n",
              "        [ 0.0023, -0.4113, -0.0379,  ...,  0.2070,  0.0524,  0.0758],\n",
              "        [-0.0339, -0.0920, -0.1736,  ...,  0.0192,  0.0396,  0.1170],\n",
              "        [ 0.1266,  0.1399, -0.2356,  ..., -0.1354,  0.0479,  0.0124]],\n",
              "       device='cuda:0', grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG3Yrz74ecL6",
        "outputId": "c7f5a122-8ac1-4978-a856-1d6ed3c06855"
      },
      "source": [
        "encoder_outputs.shape"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrHflPEqlRYP"
      },
      "source": [
        ""
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HviZePj9Lhio"
      },
      "source": [
        "\n",
        "\n",
        "Finally our Encoder is fully ready. Now let's look at the class we wrote in the last class to see what we missed!\n",
        "\n",
        "```\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqw_dxdTlclH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fL95DNdl8yg"
      },
      "source": [
        "attn_weight_layer = nn.Linear(256 * 2, 1).to(device)"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlrNmOC2lY9p"
      },
      "source": [
        "def getattentioncontext(decoder_hidden ,  encoder_hidden_states , attn_weight_layer = attn_weight_layer):\n",
        "\n",
        "  \n",
        "  attn_weights = torch.zeros(encoder_hidden_states.size(0), device=device)\n",
        "  for i in range(encoder_hidden_states.size(0)):\n",
        "    \n",
        "    attn_weight = attn_weight_layer(torch.cat((decoder_hidden[0],encoder_hidden_states[i].unsqueeze(0)), 1))\n",
        "    attn_weights[i] += attn_weight[0,0]\n",
        "\n",
        "  attn_weights = attn_weights.unsqueeze(0)\n",
        "  attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "  applied_attn = torch.bmm(attn_weights.unsqueeze(0), encoder_hidden_states.unsqueeze(0))\n",
        "\n",
        "  return applied_attn , attn_weights"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii6C5obvlWUN"
      },
      "source": [
        "\n",
        "Cool! Next let's build out Decoder where we have attention in-built.\n",
        "\n",
        "# Decoder with Attention\n",
        "\n",
        "Here is the plan. \n",
        "\n",
        "1. First input to the decoder will be SOS_token, later inputs would be the words it predicted (unless we implement teacher forcing)\n",
        "2. decoder/GRU's hidden state will be initialized with the encoder's last hidden state\n",
        "3. we will use gru's hidden state and last prediction to generate attention weight using a FC layer. \n",
        "4. this attention weight will be used to weigh the encoder_outputs using batch matric multiplication. This will give us a NEW view on how to look at encoder_states.\n",
        "5. this attention applied encoder_states will then be concatenated with the input, and then sent a linear layer and _then_ sent to the GRU. \n",
        "6. GRU's output will be sent to a FC layer to predict one of the output_language words\n",
        "\n",
        "Let's prepare all the inputs we need to do this\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cdxYvTxLf2p"
      },
      "source": [
        "# first input\n",
        "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "decoder_hidden = encoder_hidden\n",
        "decoder_cell = encoder_cell\n",
        "decoded_words = []"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAov5UD1LnXS",
        "outputId": "54d750bd-7dcd-492d-8100-491de2b15991"
      },
      "source": [
        "output_size = output_lang.n_words\n",
        "embedding = nn.Embedding(output_size, 256).to(device)\n",
        "embedded = embedding(decoder_input)\n",
        "embedded.shape"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_XopE1JLtbq"
      },
      "source": [
        "#attn_weight_layer = nn.Linear(256 * 2, 10).to(device)"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28G-Rnh3mGEJ",
        "outputId": "22a6e613-2e9c-420f-8b5b-5e9df29df5cc"
      },
      "source": [
        "print(encoder_outputs)"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1583,  0.0385, -0.2244,  ...,  0.0195, -0.0184,  0.1081],\n",
            "        [-0.2009, -0.2267, -0.1101,  ...,  0.1206, -0.1139, -0.0528],\n",
            "        [-0.1905, -0.1416,  0.0205,  ..., -0.0568, -0.0424, -0.0385],\n",
            "        ...,\n",
            "        [ 0.0023, -0.4113, -0.0379,  ...,  0.2070,  0.0524,  0.0758],\n",
            "        [-0.0339, -0.0920, -0.1736,  ...,  0.0192,  0.0396,  0.1170],\n",
            "        [ 0.1266,  0.1399, -0.2356,  ..., -0.1354,  0.0479,  0.0124]],\n",
            "       device='cuda:0', grad_fn=<CopySlices>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE2Bh28iMYQt",
        "outputId": "88d07cfc-173c-4027-e62a-bdf7813aeddf"
      },
      "source": [
        "embedded.shape, decoder_hidden.shape"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 256]), torch.Size([1, 1, 256]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUua9VbCMcNe",
        "outputId": "a5f7e91f-b3b1-4375-dfcf-10d1492648df"
      },
      "source": [
        "torch.cat((embedded,decoder_hidden),1).shape"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF1wrEc4MjJF",
        "outputId": "ba146901-7473-4bc9-f4e2-ad2f3c5c717f"
      },
      "source": [
        "torch.cat((embedded[0],decoder_hidden[0]),1).shape"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP3Si6yEMoim"
      },
      "source": [
        "# attn_weight_layer = nn.Linear(256 * 2, 10).to(device)\n",
        "# attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "# attn_weights"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bft74sQjmmhz",
        "outputId": "fcb5f47d-565f-4498-c43f-ddf78bbd10ba"
      },
      "source": [
        "attn_applied ,attn_weights = getattentioncontext(decoder_hidden ,  encoder_outputs , attn_weight_layer = attn_weight_layer)\n",
        "attn_applied.shape,attn_weights"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 256]),\n",
              " tensor([[0.1322, 0.1255, 0.1174, 0.1298, 0.1230, 0.1209, 0.1258, 0.1253]],\n",
              "        device='cuda:0', grad_fn=<SoftmaxBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELW2I1c4oYX4",
        "outputId": "fe0039af-c2e4-4e3d-c68a-3da3077fc799"
      },
      "source": [
        "output_size = output_lang.n_words\n",
        "embedding = nn.Embedding(output_size, 256).to(device)\n",
        "embedded = embedding(decoder_input)\n",
        "embedded.shape"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PvbMjGSQhjA"
      },
      "source": [
        "So, now we have this 256dm attn_applied encoder_outputs capturing what we should focus on on this step. We also have the input we already generated. That's 256dm again. GRU is gonna take 256 only. So we need to concatenate them, send to a linear layer to reduce dimensions, and then send to Gru\n",
        "![image](https://static.wikia.nocookie.net/mycun-the-movie/images/c/c2/Gru-icon.png/revision/latest/scale-to-width-down/250?cb=20151223171656)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQzy9q41N61z",
        "outputId": "4b417991-07bd-41ec-f240-21e2f2ecaa21"
      },
      "source": [
        "input_to_lstm_layer = nn.Linear(256 * 2, 256).to(device)\n",
        "\n",
        "embedded.shape, attn_applied.shape"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 256]), torch.Size([1, 1, 256]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoDPsP3-QfKT",
        "outputId": "e7b3423f-ff17-4e47-c737-545926c52b3e"
      },
      "source": [
        "torch.cat((embedded, attn_applied), 1).shape, torch.cat((embedded[0], attn_applied[0]), 1).shape"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 2, 256]), torch.Size([1, 512]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-5a0820QtLM",
        "outputId": "15e0d972-c8b5-46cf-eea8-045f1b2b7a09"
      },
      "source": [
        "input_to_lstm = input_to_lstm_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "input_to_lstm.shape"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCxDxmecQ3S3",
        "outputId": "5b3b79eb-c3bf-4b03-ed14-ca357987c552"
      },
      "source": [
        "lstm = nn.LSTM(256,256).to(device)\n",
        "input_to_lstm.shape"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq2_crTARKS7",
        "outputId": "9dc7caaa-3d75-4cd9-e904-b12909cd8ad6"
      },
      "source": [
        "input_to_lstm = input_to_lstm_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "input_to_lstm = input_to_lstm.unsqueeze(0)\n",
        "decoder_hidden.shape,input_to_lstm.shape"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 256]), torch.Size([1, 1, 256]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ14eJw7R_aa"
      },
      "source": [
        "decoder_cell=encoder_cell"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UNK7HxRRZLd",
        "outputId": "d2e850e0-e062-495d-ee9e-0d39ad309341"
      },
      "source": [
        "output,(decoder_hidden,decoder_cell) = lstm(input_to_lstm,(decoder_hidden,decoder_cell))\n",
        "output.shape,input_to_lstm.shape"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 256]), torch.Size([1, 1, 256]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5RetyPORsL2"
      },
      "source": [
        "output_word_layer = nn.Linear(256, output_lang.n_words).to(device)"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIaqBXlwScwA",
        "outputId": "3b16ac61-c281-4c5e-91a1-15524bdc7717"
      },
      "source": [
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "output, output.shape"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0003, 0.0003, 0.0003,  ..., 0.0004, 0.0003, 0.0003]],\n",
              "        device='cuda:0', grad_fn=<SoftmaxBackward>), torch.Size([1, 2803]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ6wA1TOSe1e",
        "outputId": "968a5cc7-2820-408f-e791-42bf0a2aaa1f"
      },
      "source": [
        "output.data.topk(1)"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(values=tensor([[0.0004]], device='cuda:0'), indices=tensor([[2798]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AUC5Hp-aShVn",
        "outputId": "3f0f92af-b6b7-4823-c8ce-1c77e9fb14ec"
      },
      "source": [
        "top_value, top_index = output.data.topk(1)\n",
        "output_lang.index2word[top_index.item()]"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'compiling'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbeQQXaCSjau",
        "outputId": "77f60eaf-7302-4afe-befd-60537dd9cc9e"
      },
      "source": [
        "top_index.item()"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrr-AXw0qM2W"
      },
      "source": [
        "def getnextword( targetwordidx , predwordidx):\n",
        "\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  if use_teacher_forcing:\n",
        "    wordidx = targetwordidx\n",
        "  else:\n",
        "    wordidx = predwordidx\n",
        "\n",
        "  print(use_teacher_forcing , wordidx)\n",
        "\n",
        "  return wordidx"
      ],
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW7QYXWFqOMQ"
      },
      "source": [
        "predicted_sentence =[]\n",
        "teacher_forcing_ratio = 0.5\n",
        "wordcounter = 0"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXpF9yDVSmPE",
        "outputId": "0e8de4f8-7331-4712-ecd9-49c646691ca6"
      },
      "source": [
        "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "decoder_hidden = encoder_hidden\n",
        "decoder_cell = encoder_cell\n",
        "\n",
        "output_size = output_lang.n_words\n",
        "embedding = nn.Embedding(output_size, 256).to(device)\n",
        "embedded = embedding(decoder_input)\n",
        "\n",
        "# attn_weight_layer = nn.Linear(256 * 2, 10).to(device)\n",
        "# attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "# attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "# attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "attn_applied ,attn_weights = getattentioncontext(decoder_hidden ,  encoder_outputs , attn_weight_layer = attn_weight_layer)\n",
        "\n",
        "input_to_lstm_layer = nn.Linear(256 * 2, 256).to(device)\n",
        "input_to_lstm = input_to_lstm_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "lstm = nn.LSTM(256, 256).to(device)\n",
        "input_to_lstm = input_to_lstm.unsqueeze(0)\n",
        "output, (decoder_hidden, decoder_cell) = lstm(input_to_lstm, (decoder_hidden, decoder_cell))\n",
        "output_word_layer = nn.Linear(256, output_lang.n_words).to(device)\n",
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "top_value, top_index = output.data.topk(1)\n",
        "predicted_sentence.append(output_lang.index2word[top_index.item()])\n",
        "output_lang.index2word[top_index.item()],attn_weights"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('potatoes',\n",
              " tensor([[0.1322, 0.1255, 0.1174, 0.1298, 0.1230, 0.1209, 0.1258, 0.1253]],\n",
              "        device='cuda:0', grad_fn=<SoftmaxBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-fWv-e2TyFy",
        "outputId": "507ee91f-712c-4257-e130-61808ba3a188"
      },
      "source": [
        "nextwordidx = getnextword(target_indices[wordcounter], top_index.item())\n",
        "\n",
        "wordcounter += 1\n"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False 2143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4hbzCi2VQDf",
        "outputId": "08d282a7-8ed9-45e1-822b-285a043cb667"
      },
      "source": [
        "decoder_input = torch.tensor([[nextwordidx]], device=device)\n",
        "decoder_hidden = encoder_hidden\n",
        "decoder_cell = encoder_cell\n",
        "\n",
        "output_size = output_lang.n_words\n",
        "embedding = nn.Embedding(output_size, 256).to(device)\n",
        "embedded = embedding(decoder_input)\n",
        "\n",
        "# attn_weight_layer = nn.Linear(256 * 2, 10).to(device)\n",
        "# attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "# attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "# attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "attn_applied ,attn_weights = getattentioncontext(decoder_hidden ,  encoder_outputs , attn_weight_layer = attn_weight_layer)\n",
        "\n",
        "input_to_lstm_layer = nn.Linear(256 * 2, 256).to(device)\n",
        "input_to_lstm = input_to_lstm_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "lstm = nn.LSTM(256, 256).to(device)\n",
        "input_to_lstm = input_to_lstm.unsqueeze(0)\n",
        "output, (decoder_hidden, decoder_cell) = lstm(input_to_lstm, (decoder_hidden, decoder_cell))\n",
        "output_word_layer = nn.Linear(256, output_lang.n_words).to(device)\n",
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "top_value, top_index = output.data.topk(1)\n",
        "predicted_sentence.append(output_lang.index2word[top_index.item()])\n",
        "output_lang.index2word[top_index.item()],attn_weights"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('oddly',\n",
              " tensor([[0.1322, 0.1255, 0.1174, 0.1298, 0.1230, 0.1209, 0.1258, 0.1253]],\n",
              "        device='cuda:0', grad_fn=<SoftmaxBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXvzvJvEVVde",
        "outputId": "00d315c7-ab15-4e5a-9dac-f0181c21fda4"
      },
      "source": [
        "nextwordidx = getnextword(target_indices[wordcounter], top_index.item())\n",
        "\n",
        "wordcounter += 1"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrsMUGJEqjb-",
        "outputId": "0056ea96-9c5a-4bce-8913-e547fdb888a5"
      },
      "source": [
        "decoder_input = torch.tensor([[nextwordidx]], device=device)\n",
        "decoder_hidden = encoder_hidden\n",
        "decoder_cell = encoder_cell\n",
        "\n",
        "output_size = output_lang.n_words\n",
        "embedding = nn.Embedding(output_size, 256).to(device)\n",
        "embedded = embedding(decoder_input)\n",
        "\n",
        "# attn_weight_layer = nn.Linear(256 * 2, 10).to(device)\n",
        "# attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "# attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "# attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "attn_applied ,attn_weights = getattentioncontext(decoder_hidden ,  encoder_outputs , attn_weight_layer = attn_weight_layer)\n",
        "\n",
        "input_to_lstm_layer = nn.Linear(256 * 2, 256).to(device)\n",
        "input_to_lstm = input_to_lstm_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "lstm = nn.LSTM(256, 256).to(device)\n",
        "input_to_lstm = input_to_lstm.unsqueeze(0)\n",
        "output, (decoder_hidden, decoder_cell) = lstm(input_to_lstm, (decoder_hidden, decoder_cell))\n",
        "output_word_layer = nn.Linear(256, output_lang.n_words).to(device)\n",
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "top_value, top_index = output.data.topk(1)\n",
        "predicted_sentence.append(output_lang.index2word[top_index.item()])\n",
        "output_lang.index2word[top_index.item()],attn_weights"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('resentful',\n",
              " tensor([[0.1322, 0.1255, 0.1174, 0.1298, 0.1230, 0.1209, 0.1258, 0.1253]],\n",
              "        device='cuda:0', grad_fn=<SoftmaxBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdM-KJFIqr6d",
        "outputId": "26600f82-4602-4eb9-e05e-4ac2440b20ac"
      },
      "source": [
        "nextwordidx = getnextword(target_indices[wordcounter], top_index.item())\n",
        "\n",
        "wordcounter += 1"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True 1302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1EDGZSlqxso",
        "outputId": "e5f44ab7-e137-4733-e3e6-c641ca1408d5"
      },
      "source": [
        "decoder_input = torch.tensor([[nextwordidx]], device=device)\n",
        "decoder_hidden = encoder_hidden\n",
        "decoder_cell = encoder_cell\n",
        "\n",
        "output_size = output_lang.n_words\n",
        "embedding = nn.Embedding(output_size, 256).to(device)\n",
        "embedded = embedding(decoder_input)\n",
        "\n",
        "# attn_weight_layer = nn.Linear(256 * 2, 10).to(device)\n",
        "# attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "# attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "# attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "attn_applied ,attn_weights = getattentioncontext(decoder_hidden ,  encoder_outputs , attn_weight_layer = attn_weight_layer)\n",
        "\n",
        "input_to_lstm_layer = nn.Linear(256 * 2, 256).to(device)\n",
        "input_to_lstm = input_to_lstm_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "lstm = nn.LSTM(256, 256).to(device)\n",
        "input_to_lstm = input_to_lstm.unsqueeze(0)\n",
        "output, (decoder_hidden, decoder_cell) = lstm(input_to_lstm, (decoder_hidden, decoder_cell))\n",
        "output_word_layer = nn.Linear(256, output_lang.n_words).to(device)\n",
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "top_value, top_index = output.data.topk(1)\n",
        "predicted_sentence.append(output_lang.index2word[top_index.item()])\n",
        "output_lang.index2word[top_index.item()],attn_weights"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('normal',\n",
              " tensor([[0.1322, 0.1255, 0.1174, 0.1298, 0.1230, 0.1209, 0.1258, 0.1253]],\n",
              "        device='cuda:0', grad_fn=<SoftmaxBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHvLbLCRqvxW",
        "outputId": "0496304a-cf34-47ea-cf73-689efb9cbce0"
      },
      "source": [
        "nextwordidx = getnextword(target_indices[wordcounter], top_index.item())\n",
        "\n",
        "wordcounter += 1"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False 109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UecXVI3Jq1yB",
        "outputId": "9e958cd0-7c80-4487-c491-4c0f41b6450f"
      },
      "source": [
        "decoder_input = torch.tensor([[nextwordidx]], device=device)\n",
        "decoder_hidden = encoder_hidden\n",
        "decoder_cell = encoder_cell\n",
        "\n",
        "output_size = output_lang.n_words\n",
        "embedding = nn.Embedding(output_size, 256).to(device)\n",
        "embedded = embedding(decoder_input)\n",
        "\n",
        "# attn_weight_layer = nn.Linear(256 * 2, 10).to(device)\n",
        "# attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "# attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "# attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "attn_applied ,attn_weights = getattentioncontext(decoder_hidden ,  encoder_outputs , attn_weight_layer = attn_weight_layer)\n",
        "\n",
        "input_to_lstm_layer = nn.Linear(256 * 2, 256).to(device)\n",
        "input_to_lstm = input_to_lstm_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "lstm = nn.LSTM(256, 256).to(device)\n",
        "input_to_lstm = input_to_lstm.unsqueeze(0)\n",
        "output, (decoder_hidden, decoder_cell) = lstm(input_to_lstm, (decoder_hidden, decoder_cell))\n",
        "output_word_layer = nn.Linear(256, output_lang.n_words).to(device)\n",
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "top_value, top_index = output.data.topk(1)\n",
        "predicted_sentence.append(output_lang.index2word[top_index.item()])\n",
        "\n",
        "output_lang.index2word[top_index.item()],attn_weights"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('trance',\n",
              " tensor([[0.1322, 0.1255, 0.1174, 0.1298, 0.1230, 0.1209, 0.1258, 0.1253]],\n",
              "        device='cuda:0', grad_fn=<SoftmaxBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDIkbocBqwu1",
        "outputId": "0d05969e-2811-4017-96ac-5d5e791d29be"
      },
      "source": [
        "nextwordidx = getnextword(target_indices[wordcounter], top_index.item())\n",
        "\n",
        "wordcounter += 1"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False 2596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZu2Tm4dq3W8",
        "outputId": "75d64b5a-8c69-40bb-b984-b3820af78eb1"
      },
      "source": [
        "decoder_input = torch.tensor([[nextwordidx]], device=device)\n",
        "decoder_hidden = encoder_hidden\n",
        "decoder_cell = encoder_cell\n",
        "\n",
        "output_size = output_lang.n_words\n",
        "embedding = nn.Embedding(output_size, 256).to(device)\n",
        "embedded = embedding(decoder_input)\n",
        "\n",
        "# attn_weight_layer = nn.Linear(256 * 2, 10).to(device)\n",
        "# attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "# attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "# attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "attn_applied ,attn_weights = getattentioncontext(decoder_hidden ,  encoder_outputs , attn_weight_layer = attn_weight_layer)\n",
        "\n",
        "input_to_lstm_layer = nn.Linear(256 * 2, 256).to(device)\n",
        "input_to_lstm = input_to_lstm_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "lstm = nn.LSTM(256, 256).to(device)\n",
        "input_to_lstm = input_to_lstm.unsqueeze(0)\n",
        "output, (decoder_hidden, decoder_cell) = lstm(input_to_lstm, (decoder_hidden, decoder_cell))\n",
        "output_word_layer = nn.Linear(256, output_lang.n_words).to(device)\n",
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "top_value, top_index = output.data.topk(1)\n",
        "predicted_sentence.append(output_lang.index2word[top_index.item()])\n",
        "output_lang.index2word[top_index.item()],attn_weights"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('beggar',\n",
              " tensor([[0.1322, 0.1255, 0.1174, 0.1298, 0.1230, 0.1209, 0.1258, 0.1253]],\n",
              "        device='cuda:0', grad_fn=<SoftmaxBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUOaI5oHqwcr",
        "outputId": "dda7779e-4ab8-48ad-976d-3dffb34d2742"
      },
      "source": [
        "nextwordidx = getnextword(target_indices[wordcounter], top_index.item())\n",
        "\n",
        "wordcounter += 1"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True 129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV1R2Y8wq9PF",
        "outputId": "59dfd2b7-2149-4043-a5c8-0821c8c4ebe5"
      },
      "source": [
        "target_indices, output_sentence , ' '.join(predicted_sentence) , input_sentence\n"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([2, 16, 1302, 532, 571, 129, 4, 0],\n",
              " 'i am willing to help you .',\n",
              " 'potatoes oddly resentful normal trance beggar',\n",
              " 'je suis desireux de vous aider .')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1gi8IizVct6",
        "outputId": "61e792b1-a2e4-4aed-c781-a71824e84c1d"
      },
      "source": [
        "pred_sentence = []\n",
        "\n",
        "decoder_hidden = torch.zeros(1, 1, 256, device=device)\n",
        "decoder_cell = torch.zeros(1, 1, 256, device=device)\n",
        "\n",
        "for i in range(7):\n",
        "  decoder_input = torch.tensor([[target_indices[i]]], device=device)\n",
        "  \n",
        "  output_size = output_lang.n_words\n",
        "  embedded = embedding(decoder_input)\n",
        "  \n",
        "  attn_applied , attn_weights = getattentioncontext(decoder_hidden , encoder_hidden_states)\n",
        "  \n",
        "  input_to_lstm = input_to_lstm_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "  input_to_lstm = input_to_lstm.unsqueeze(0)\n",
        "  output, (decoder_hidden,decoder_cell) = lstm(input_to_lstm, (decoder_hidden,decoder_cell))\n",
        "\n",
        "  output = F.relu(output)\n",
        "  output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "  top_value, top_index = output.data.topk(1)\n",
        "  pred_sentence.append(output_lang.index2word[top_index.item()])\n",
        "  print(output_sentence.split(\" \")[i], target_indices[i], output_lang.index2word[top_index.item()], top_index.item() )\n",
        "  print(attn_weights)"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i 2 downtown 1044\n",
            "tensor([[0.1747, 0.1664, 0.1711, 0.1623, 0.1606, 0.1648]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "am 16 obsessed 2357\n",
            "tensor([[0.1747, 0.1664, 0.1711, 0.1623, 0.1606, 0.1648]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "willing 1302 obsessed 2357\n",
            "tensor([[0.1747, 0.1664, 0.1711, 0.1623, 0.1606, 0.1648]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "to 532 beggar 786\n",
            "tensor([[0.1747, 0.1664, 0.1711, 0.1623, 0.1606, 0.1648]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "help 571 beggar 786\n",
            "tensor([[0.1747, 0.1664, 0.1711, 0.1623, 0.1606, 0.1648]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "you 129 beggar 786\n",
            "tensor([[0.1747, 0.1664, 0.1711, 0.1623, 0.1606, 0.1648]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            ". 4 beggar 786\n",
            "tensor([[0.1747, 0.1664, 0.1711, 0.1623, 0.1606, 0.1648]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WerMg2wrV6HM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c63743-7325-40f1-cc95-9fc91249db7b"
      },
      "source": [
        "target_indices, output_sentence , ' '.join(predicted_sentence) , input_sentence\n"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([2, 16, 1302, 532, 571, 129, 4, 0],\n",
              " 'i am willing to help you .',\n",
              " 'potatoes oddly resentful normal trance beggar',\n",
              " 'je suis desireux de vous aider .')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y788pRJ4sPOB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}